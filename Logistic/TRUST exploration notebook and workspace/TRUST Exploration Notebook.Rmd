---
title: "R Notebook"
output: 
  html_notebook: 
    highlight: zenburn
    theme: flatly
---

```{r, message=FALSE, warning=FALSE}
library(tidyverse)
library(sjlabelled)
library(ROCR)
library(leaps)
```

***Starting from pre-processed data, further clean and prepare data for logistic regression model search***  
```{r}
survey <- haven::read_sav("cleaned_extra.sav")
# survey <- haven::read_sav("dem_only.sav")

# remove SOCTRUST columns for processing and later re-append
surveyA <- subset (survey, select = -c(SOCASSIGN_W32,SOCTRUST_W32,SOCTRUST2_W32,SOCTRUST3_W32,SOCTRUST4_W32,SOCTRUST5_W32))
# also remove DIVISION_BY_MSA
surveyA <- subset (surveyA, select = -c(DIVISION_BY_MSA))
# select 2-level SOCTRUST columns we want to keep and process
surveyB <- subset (survey, select = c(SOCTRUST_W32,SOCTRUST2_W32,SOCTRUST5_W32))

# keep 4-level SOCTRUST column for condensing
surveyC <- subset (survey, select = SOCTRUST4_W32)

# condense 1,2 to 1, and 3,4 to 2 in SOCTRUST4
surveyC[surveyC==2] <- 1 
surveyC[surveyC==3] <- 2
surveyC[surveyC==4] <- 2

surveyBC <- cbind(surveyB,surveyC)

# collapse all columns to one
surveyBC$TRUST <-apply(surveyBC, 1, function(x) paste(x[!is.na(x)]))

# fix class
TRUST <- as.numeric(surveyBC$TRUST)

# put it back together
surveyD <- cbind(surveyA,TRUST)

# exclude THERMs from factors
surveyD <- surveyD %>%
  mutate(across(!contains("THERM"), ~ replace(.x, .x==99, NA))) %>%
  mutate(across(contains("THERM"), ~ replace(.x, .x==999, NA))) %>%
  mutate(across(!contains("THERM"), to_factor))

# surveyD is what we will work with
surveyD <- surveyD[complete.cases(surveyD),]

# unfactor WEIGHT_W32
surveyD$WEIGHT_W32 <- as.numeric(surveyD$WEIGHT_W32)
```

***Split data into Train and Test***  
```{r}
set.seed(1)
sample<-sample.int(nrow(surveyD), floor(.80*nrow(surveyD)), replace = F)
train<-surveyD[sample, ]
test<-surveyD[-sample, ]
```
***Create logistic model from entire Training set except THERM vars.***  
***Use this as initial exploration***  
```{r}
fullmod <- glm(TRUST ~ . -THERMOBAMA_W32 -THERMPENCE_W32 -THERMTRUMP_W32 -WEIGHT_W32, family = 'binomial', data=train)
summary(fullmod)
```
  
***Do backwards selection on the full model, seeking most useful predictors.***  
```{r}
backwards <- step(fullmod) # Backwards selection is the default
```

***Validate the full model on the test data by creating an ROC curve.***  
```{r}
preds<-predict(backwards,newdata=test, type="response")

##produce the numbers associated with classification table
rates<-prediction(preds, test$TRUST)

##store the true positive and false postive rates
roc_result<-performance(rates,measure="tpr", x.measure="fpr")

##plot ROC curve and overlay the diagonal line for random guessing
plot(roc_result, main="ROC Curve for TRUST")
lines(x = c(0,1), y = c(0,1), col="red")

##compute the AUC
auc<-performance(rates, measure = "auc")
auc@y.values

##confusion matrix. Actual values in the rows, predicted classification in cols
table(test$TRUST, preds>0.5)
mytab <- table(test$TRUST, preds>0.5)

TP <- mytab[2,2]
TN <- mytab[1,1]
FP <- mytab[1,2]
FN <- mytab[2,1]
Accuracy <- (TP + TN) / (TP+TN+FP+FN)  
print(paste("Accuracy", Accuracy))

print(paste("False Positive Rate:", FP/(TN+FP)))
print(paste("False Negative Rate:", FN/(FN+TP)))
table(train$TRUST)
table(test$TRUST)
```

***Run the obtained model to check predictor significance values.***  
```{r}
result <- glm(TRUST ~ SATLIFEB_W32 + SATLIFEE_W32 + COMATTACH_W32 + FEELA_W32 + 
                FEELB_W32 + FEELC_W32 + INC_W32 + COMMIMPC_W32 + FEDSHAREB_W32 + 
                LOCALPROBB_W32 + LOCALPROBD_W32 + LOCALPROBG_W32 + LOCALPROBI_W32 + 
                VALUEURBAN_W32 + NEIGHSAMEB_W32 + NEIGHSAMEC_W32 + IMMCULT2_W32 + 
                WOMENOPPS_W32 + WHADVANT_W32 + GAYMARR2_W32 + F_CREGION_FINAL + 
                F_INTUSER_FINAL + F_RACE + F_AGECAT_FINAL + F_INCOME_RECODE_FINAL + 
                F_VOLSUM_FINAL + F_IDEO_FINAL, family = "binomial", data=train)
summary(result)
```
***For comparison, run a model using only the significant demographic predictors from above.***  
```{r}
result2 <- glm(TRUST ~ 
                F_INTUSER_FINAL + F_RACE + F_AGECAT_FINAL + F_INCOME_RECODE_FINAL + 
                F_VOLSUM_FINAL, family = "binomial", data=train)
summary(result2)
```
  
***Validate this demographic-only model on the test data by creating an ROC curve.***  
```{r}
preds<-predict(result2,newdata=test, type="response")

##produce the numbers associated with classification table
rates<-prediction(preds, test$TRUST)

##store the true positive and false postive rates
roc_result<-performance(rates,measure="tpr", x.measure="fpr")

##plot ROC curve and overlay the diagonal line for random guessing
plot(roc_result, main="ROC Curve for TRUST")
lines(x = c(0,1), y = c(0,1), col="red")

##compute the AUC
auc<-performance(rates, measure = "auc")
auc@y.values

##confusion matrix. Actual values in the rows, predicted classification in cols
table(test$TRUST, preds>0.5)
mytab <- table(test$TRUST, preds>0.5)

TP <- mytab[2,2]
TN <- mytab[1,1]
FP <- mytab[1,2]
FN <- mytab[2,1]
Accuracy <- (TP + TN) / (TP+TN+FP+FN)  
print(paste("Accuracy", Accuracy))

print(paste("False Positive Rate:", FP/(TN+FP)))
print(paste("False Negative Rate:", FN/(FN+TP)))
table(train$TRUST)
table(test$TRUST)
```
